{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models with M&Ms-2 Dataset\n",
    "\n",
    "This tutorial illustrates how to use MONAI for training a denoising diffusion probabilistic model (DDPM)[1] to create\n",
    "synthetic 2D images.\n",
    "\n",
    "[1] - Ho et al. \"Denoising Diffusion Probabilistic Models\" https://arxiv.org/abs/2006.11239\n",
    "\n",
    "\n",
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrimm\\.conda\\envs\\ddpm\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 1.13.1+cu116\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: c:\\Users\\jrimm\\.conda\\envs\\ddpm\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "Nibabel version: 5.0.1\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.1\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu116\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.0.0\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.21.3\n",
      "mlflow version: 2.2.2\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "from generative.networks.schedulers import DDIMScheduler, DDPMScheduler, PNDMScheduler\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the MONAI_DATA_DIRECTORY environment variable.\n",
    "\n",
    "This allows you to save results and reuse downloads.\n",
    "\n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrimm\\AppData\\Local\\Temp\\tmpwsg30n3w\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup M&Ms-2 Dataset and training and validation dataloaders\n",
    "Combine Sina's implementation to import M&Ms-2 dataset (https://www.ub.edu/mnms-2/) manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Current device is on 0\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "torch.Size([874, 1, 128, 128, 1])\n",
      "874\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "from modules.dataloader import CMRCineDataModule\n",
    "import argparse\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH = os.path.join(os.getcwd(), \"dataset_3D_crop_small\")\n",
    "RUN_NAME = \"cmr_DDPM_17042023\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print('Device is {}'.format(DEVICE))\n",
    "print(\"Current device is on\", torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# set your own path here, eg, '/home/bme001/20180883/data/mnms2/sorted/SA/PerDisease' (Linux style path)\n",
    "default_config = {\n",
    "    'dataset_path': PATH,\n",
    "    'run_name': RUN_NAME,\n",
    "    'epochs': 100,\n",
    "    'log_interval': 100,\n",
    "    'batch_size' : 8,\n",
    "    'image_size' : 128,\n",
    "    'num_workers' : 0,  # default 8, windows cannot handle this\n",
    "    'device' : DEVICE,\n",
    "    'lr' : 3e-4,\n",
    "    'noise_steps' : 500,\n",
    "    'beta_start': 1e-4,\n",
    "    'beta_end': 0.01,\n",
    "    }\n",
    "\n",
    "# set key-value pairs from command line \n",
    "parser = argparse.ArgumentParser()\n",
    "for keys in default_config:\n",
    "    parser.add_argument('--'+keys, default=default_config[keys], type= type(default_config[keys]))\n",
    "args = parser.parse_args()\n",
    "\n",
    "# CMR2DDataModule or CMRCineDataModule class\n",
    "data = CMRCineDataModule(\n",
    "        data_dir = args.dataset_path,\n",
    "        image_size = args.image_size,\n",
    "        batch_size = args.batch_size,\n",
    "        train_val_ratio = 0.8,\n",
    "        num_workers = args.num_workers,\n",
    "    )\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "\n",
    "train_loader = data.train_dataloader()\n",
    "val_loader = data.val_dataloader()\n",
    "\n",
    "print(train_loader.dataset.__len__())\n",
    "print(val_loader.dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size = 8\n",
      "Number of batches in train_dataloader = 110\n",
      "Number of batches in val_dataloader = 82\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[0;32m      7\u001b[0m \u001b[39m# The dictionary is not needed for the training but not first priority to remove it\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      9\u001b[0m \u001b[39m# print(batch['image']['data'].squeeze(-1))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmax()) \u001b[39m# TO DO: Why is the max value not 1.0?\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "print('Batch_size = {}'.format(args.batch_size))\n",
    "print('Number of batches in train_dataloader = {}'.format(len(train_loader)))\n",
    "print('Number of batches in val_dataloader = {}'.format(len(val_loader)))\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# The dictionary is not needed for the training but not first priority to remove it\n",
    "print(batch['image']['data'].squeeze(-1).shape)\n",
    "# print(batch['image']['data'].squeeze(-1))\n",
    "print(batch['image']['data'].squeeze(-1).max()) # TO DO: Why is the max value not 1.0?\n",
    "print(batch['image']['data'].squeeze(-1).min()) # TO DO: Why is the min value not -1.0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_batch\n\u001b[0;32m      3\u001b[0m \u001b[39m# TO DO: Filter out the useless slices\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plot_batch(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\jrimm\\Documents\\tue\\cmr_diffusion_models\\modules\\utils.py:113\u001b[0m, in \u001b[0;36mplot_batch\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_batch\u001b[39m(dataloader):\n\u001b[0;32m    111\u001b[0m     batch \u001b[39m=\u001b[39m tio\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mget_first_item(dataloader)\n\u001b[1;32m--> 113\u001b[0m     fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(batch[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[0;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m ax, im \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(axes\u001b[39m.\u001b[39mflatten(), batch[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m    115\u001b[0m         ax\u001b[39m.\u001b[39mimshow(im\u001b[39m.\u001b[39msqueeze(), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "from modules.utils import plot_batch\n",
    "\n",
    "# TO DO: Filter out the useless slices\n",
    "plot_batch(train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(train_loader)\n",
    "print(f\"batch shape: {check_data['image']['data'].shape}\")\n",
    "# print(check_data[\"image\"]['data'][0, 0].shape)\n",
    "image_visualisation = torch.cat(\n",
    "    [check_data[\"image\"]['data'][0, 0], check_data[\"image\"]['data'][1, 0], \\\n",
    "        check_data[\"image\"]['data'][2, 0], check_data[\"image\"]['data'][3, 0]], dim=1\n",
    ")\n",
    "print(check_data[\"image\"]['data'][0, 0].max())\n",
    "print(check_data[\"image\"]['data'][0, 0].min())\n",
    "plt.figure(\"training images\", (12, 6))\n",
    "# plt.imshow(image_visualisation, vmin=-1, vmax=1, cmap=\"gray\")    # TO DO: vmin and vmax are not correct?\n",
    "plt.imshow(image_visualisation, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network, scheduler, optimizer, and inferer\n",
    "At this step, we instantiate the MONAI components to create a DDPM, the UNET, the noise scheduler, and the inferer used for training and sampling. We are using\n",
    "the original DDPM scheduler containing 1000 timesteps in its Markov chain, and a 2D UNET with attention mechanisms\n",
    "in the 2nd and 3rd levels, each with 1 attention head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "device = torch.device(args.device)\n",
    "total_timesteps = args.noise_steps\n",
    "epochs = args.epochs\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims = 2,\n",
    "    in_channels = 1,\n",
    "    out_channels = 1,\n",
    "    num_channels = (128, 256, 256),\n",
    "    attention_levels = (False, True, True),\n",
    "    num_res_blocks = 1,\n",
    "    num_head_channels = 256,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=total_timesteps)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=args.lr)\n",
    "\n",
    "inferer = DiffusionInferer(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "If you would like to skip the training and use a pre-trained model instead, set `use_pretrained=True`. This model was trained using the code in `tutorials/generative/distributed_training/ddpm_training_ddp.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from urllib3.exceptions import InsecureRequestWarning\n",
    "# from urllib3 import disable_warnings\n",
    "\n",
    "# disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# page = requests.get('https://drive.google.com', verify=False)\n",
    "\n",
    "# print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Sovle the problem with the pretrained model\n",
    "use_pretrained = False  # set to False to train the model from scratch\n",
    "\n",
    "# TO DO: Solve the problem CPU bottleneck\n",
    "if use_pretrained:\n",
    "    model = torch.hub.load(\"marksgraham/pretrained_generative_models:v0.2\", model=\"ddpm_2d\", verbose=True).to(device)\n",
    "else:\n",
    "    n_epochs = epochs\n",
    "    val_interval = 10\n",
    "    epoch_loss_list = []\n",
    "    val_epoch_loss_list = []\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    total_start = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=70)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        for step, batch in progress_bar:\n",
    "            images = batch[\"image\"]['data'].squeeze(-1).to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(enabled=True):\n",
    "                # Generate random noise\n",
    "                noise = torch.randn_like(images).to(device)\n",
    "\n",
    "                # Create timesteps\n",
    "                timesteps = torch.randint(\n",
    "                    0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
    "                ).long()\n",
    "\n",
    "                # Get model prediction\n",
    "                noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)\n",
    "\n",
    "                loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": epoch_loss / (step + 1)})\n",
    "        epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_epoch_loss = 0\n",
    "            for step, batch in enumerate(val_loader):\n",
    "                images = batch[\"image\"]['data'].squeeze(-1).to(device)\n",
    "                with torch.no_grad():\n",
    "                    with autocast(enabled=True):\n",
    "                        noise = torch.randn_like(images).to(device)\n",
    "                        timesteps = torch.randint(\n",
    "                            0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device\n",
    "                        ).long()\n",
    "                        noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)\n",
    "                        val_loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "                val_epoch_loss += val_loss.item()\n",
    "                progress_bar.set_postfix({\"val_loss\": val_epoch_loss / (step + 1)})\n",
    "            val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "\n",
    "            # Sampling image during training\n",
    "            noise = torch.randn((1, 1, 64, 64))\n",
    "            noise = noise.to(device)\n",
    "            scheduler.set_timesteps(num_inference_steps=total_timesteps)\n",
    "            with autocast(enabled=True):\n",
    "                image = inferer.sample(input_noise=noise, diffusion_model=model, scheduler=scheduler)\n",
    "\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(image[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "            plt.tight_layout()\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"train completed, total time: {total_time}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pretrained:\n",
    "    plt.style.use(\"seaborn-v0_8\")\n",
    "    plt.title(\"Learning Curves\", fontsize=20)\n",
    "    plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_loss_list, color=\"C0\", linewidth=2.0, label=\"Train\")\n",
    "    plt.plot(\n",
    "        np.linspace(val_interval, n_epochs, int(n_epochs / val_interval)),\n",
    "        val_epoch_loss_list,\n",
    "        color=\"C1\",\n",
    "        linewidth=2.0,\n",
    "        label=\"Validation\",\n",
    "    )\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.xlabel(\"Epochs\", fontsize=16)\n",
    "    plt.ylabel(\"Loss\", fontsize=16)\n",
    "    plt.legend(prop={\"size\": 14})\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting sampling process along DDPM's Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "noise = torch.randn((1, 1, 64, 64))\n",
    "noise = noise.to(device)\n",
    "scheduler.set_timesteps(num_inference_steps=total_timesteps)\n",
    "with autocast(enabled=True):\n",
    "    image, intermediates = inferer.sample(\n",
    "        input_noise=noise, diffusion_model=model, scheduler=scheduler, save_intermediates=True, intermediate_steps=50\n",
    "    )\n",
    "\n",
    "chain = torch.cat(intermediates, dim=-1)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
